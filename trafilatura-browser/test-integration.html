<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Trafilatura Browser - 完整功能集成测试</title>
    <style>
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }

      body {
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
          "Helvetica Neue", Arial, sans-serif;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        min-height: 100vh;
        padding: 20px;
      }

      .container {
        max-width: 1400px;
        margin: 0 auto;
      }

      .header {
        text-align: center;
        color: white;
        margin-bottom: 30px;
      }

      .header h1 {
        font-size: 2.5rem;
        margin-bottom: 10px;
        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.2);
      }

      .header .subtitle {
        font-size: 1.1rem;
        opacity: 0.9;
      }

      .status-banner {
        background: white;
        border-radius: 12px;
        padding: 20px;
        margin-bottom: 20px;
        box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
      }

      .status-grid {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
        gap: 15px;
      }

      .status-item {
        text-align: center;
        padding: 15px;
        background: #f8f9fa;
        border-radius: 8px;
      }

      .status-item .label {
        font-size: 0.85rem;
        color: #666;
        margin-bottom: 5px;
      }

      .status-item .value {
        font-size: 1.5rem;
        font-weight: bold;
        color: #667eea;
      }

      .main-content {
        display: grid;
        grid-template-columns: 1fr 1fr;
        gap: 20px;
      }

      .panel {
        background: white;
        border-radius: 12px;
        padding: 25px;
        box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
      }

      .panel-title {
        font-size: 1.3rem;
        font-weight: 600;
        margin-bottom: 20px;
        color: #333;
        border-bottom: 2px solid #667eea;
        padding-bottom: 10px;
      }

      .input-group {
        margin-bottom: 15px;
      }

      .input-group label {
        display: block;
        font-weight: 500;
        margin-bottom: 8px;
        color: #555;
      }

      textarea {
        width: 100%;
        min-height: 300px;
        padding: 12px;
        border: 2px solid #e0e0e0;
        border-radius: 8px;
        font-family: "Monaco", "Courier New", monospace;
        font-size: 0.9rem;
        resize: vertical;
        transition: border-color 0.3s;
      }

      textarea:focus {
        outline: none;
        border-color: #667eea;
      }

      .options-grid {
        display: grid;
        grid-template-columns: 1fr 1fr;
        gap: 15px;
        margin-bottom: 15px;
      }

      .option-item {
        display: flex;
        align-items: center;
        gap: 8px;
      }

      .option-item input[type="checkbox"] {
        width: 18px;
        height: 18px;
        cursor: pointer;
      }

      .option-item label {
        cursor: pointer;
        font-size: 0.95rem;
      }

      select,
      input[type="text"] {
        width: 100%;
        padding: 10px;
        border: 2px solid #e0e0e0;
        border-radius: 8px;
        font-size: 0.95rem;
        transition: border-color 0.3s;
      }

      select:focus,
      input[type="text"]:focus {
        outline: none;
        border-color: #667eea;
      }

      .button-group {
        display: flex;
        gap: 10px;
        margin-top: 20px;
      }

      button {
        flex: 1;
        padding: 12px 24px;
        border: none;
        border-radius: 8px;
        font-size: 1rem;
        font-weight: 600;
        cursor: pointer;
        transition: all 0.3s;
      }

      .btn-primary {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
      }

      .btn-primary:hover {
        transform: translateY(-2px);
        box-shadow: 0 5px 15px rgba(102, 126, 234, 0.4);
      }

      .btn-secondary {
        background: #f8f9fa;
        color: #333;
        border: 2px solid #e0e0e0;
      }

      .btn-secondary:hover {
        background: #e9ecef;
      }

      .result-area {
        margin-top: 15px;
      }

      .result-tabs {
        display: flex;
        gap: 5px;
        margin-bottom: 10px;
      }

      .tab {
        padding: 8px 16px;
        background: #f8f9fa;
        border: none;
        border-radius: 6px 6px 0 0;
        cursor: pointer;
        font-size: 0.9rem;
        transition: all 0.2s;
      }

      .tab.active {
        background: #667eea;
        color: white;
      }

      .tab-content {
        display: none;
      }

      .tab-content.active {
        display: block;
      }

      pre {
        background: #2d2d2d;
        color: #f8f8f2;
        padding: 15px;
        border-radius: 8px;
        overflow-x: auto;
        font-size: 0.85rem;
        line-height: 1.5;
        max-height: 600px;
        overflow-y: auto;
      }

      .metadata-grid {
        display: grid;
        gap: 10px;
      }

      .metadata-item {
        background: #f8f9fa;
        padding: 12px;
        border-radius: 6px;
        border-left: 3px solid #667eea;
      }

      .metadata-item .key {
        font-weight: 600;
        color: #666;
        font-size: 0.85rem;
        margin-bottom: 4px;
      }

      .metadata-item .value {
        color: #333;
      }

      .test-samples {
        margin-top: 15px;
      }

      .sample-btn {
        display: inline-block;
        padding: 8px 16px;
        margin: 5px;
        background: #e3f2fd;
        border: 1px solid #90caf9;
        border-radius: 6px;
        cursor: pointer;
        font-size: 0.9rem;
        transition: all 0.2s;
      }

      .sample-btn:hover {
        background: #bbdefb;
        transform: translateY(-1px);
      }

      .stats {
        display: grid;
        grid-template-columns: repeat(3, 1fr);
        gap: 10px;
        margin-top: 15px;
      }

      .stat-card {
        background: #f8f9fa;
        padding: 15px;
        border-radius: 8px;
        text-align: center;
      }

      .stat-card .label {
        font-size: 0.8rem;
        color: #666;
        margin-bottom: 5px;
      }

      .stat-card .value {
        font-size: 1.5rem;
        font-weight: bold;
        color: #667eea;
      }

      .log-panel {
        grid-column: 1 / -1;
        max-height: 300px;
      }

      .log-content {
        background: #2d2d2d;
        color: #f8f8f2;
        padding: 15px;
        border-radius: 8px;
        max-height: 250px;
        overflow-y: auto;
        font-family: "Monaco", "Courier New", monospace;
        font-size: 0.85rem;
      }

      .log-entry {
        margin-bottom: 5px;
        padding: 5px;
        border-left: 3px solid transparent;
      }

      .log-entry.info {
        border-left-color: #4caf50;
      }

      .log-entry.warn {
        border-left-color: #ff9800;
      }

      .log-entry.error {
        border-left-color: #f44336;
      }

      .loading {
        display: inline-block;
        width: 20px;
        height: 20px;
        border: 3px solid rgba(255, 255, 255, 0.3);
        border-radius: 50%;
        border-top-color: #fff;
        animation: spin 1s ease-in-out infinite;
      }

      @keyframes spin {
        to {
          transform: rotate(360deg);
        }
      }

      @media (max-width: 1024px) {
        .main-content {
          grid-template-columns: 1fr;
        }

        .options-grid {
          grid-template-columns: 1fr;
        }
      }
    </style>
  </head>
  <body>
    <div class="container">
      <!-- Header -->
      <div class="header">
        <h1>🚀 Trafilatura Browser</h1>
        <div class="subtitle">完整功能集成测试 - 阶段8-10</div>
      </div>

      <!-- Status Banner -->
      <div class="status-banner">
        <div class="status-grid">
          <div class="status-item">
            <div class="label">版本</div>
            <div class="value">1.0.0</div>
          </div>
          <div class="status-item">
            <div class="label">完成度</div>
            <div class="value" id="completionRate">99%</div>
          </div>
          <div class="status-item">
            <div class="label">测试通过</div>
            <div class="value">752/754</div>
          </div>
          <div class="status-item">
            <div class="label">代码行数</div>
            <div class="value">~9,228</div>
          </div>
          <div class="status-item">
            <div class="label">模块数</div>
            <div class="value">35</div>
          </div>
          <div class="status-item">
            <div class="label">状态</div>
            <div class="value" style="color: #4caf50">✅ 就绪</div>
          </div>
        </div>
      </div>

      <!-- Main Content -->
      <div class="main-content">
        <!-- Input Panel -->
        <div class="panel">
          <h2 class="panel-title">📥 输入配置</h2>

          <div class="input-group">
            <label>HTML输入</label>
            <textarea
              id="htmlInput"
              placeholder="在此粘贴HTML内容..."
            ></textarea>
          </div>

          <div class="test-samples">
            <label style="font-weight: 600; margin-bottom: 10px; display: block"
              >快速测试样例:</label
            >
            <button class="sample-btn" onclick="loadSample('news')">
              📰 新闻文章
            </button>
            <button class="sample-btn" onclick="loadSample('blog')">
              📝 博客文章
            </button>
            <button class="sample-btn" onclick="loadSample('tech')">
              💻 技术文档
            </button>
            <button class="sample-btn" onclick="loadSample('chinese')">
              🀄 中文内容
            </button>
            <button class="sample-btn" onclick="loadSample('complex')">
              🌐 复杂页面
            </button>
            <button class="sample-btn" onclick="loadSample('ecommerce')">
              🛒 电商产品
            </button>
            <button class="sample-btn" onclick="loadSample('recipe')">
              🍳 菜谱页面
            </button>
            <button class="sample-btn" onclick="loadSample('research')">
              📚 学术论文
            </button>
          </div>

          <div class="input-group" style="margin-top: 20px">
            <label>输出格式</label>
            <select id="formatSelect">
              <option value="txt">TXT (纯文本)</option>
              <option value="markdown" selected>Markdown</option>
              <option value="json">JSON</option>
              <option value="csv">CSV</option>
              <option value="xml">XML</option>
              <option value="tei">TEI-XML</option>
              <option value="python">Python (字典)</option>
            </select>
          </div>

          <div class="input-group">
            <label>提取策略</label>
            <select id="focusSelect">
              <option value="balanced" selected>Balanced (平衡)</option>
              <option value="precision">Precision (精确)</option>
              <option value="recall">Recall (召回)</option>
            </select>
          </div>

          <div class="input-group">
            <label>URL (可选)</label>
            <input
              type="text"
              id="urlInput"
              placeholder="https://example.com/article"
            />
          </div>

          <div class="options-grid">
            <div class="option-item">
              <input type="checkbox" id="opt-metadata" checked />
              <label for="opt-metadata">包含元数据</label>
            </div>
            <div class="option-item">
              <input type="checkbox" id="opt-comments" checked />
              <label for="opt-comments">提取评论</label>
            </div>
            <div class="option-item">
              <input type="checkbox" id="opt-tables" checked />
              <label for="opt-tables">包含表格</label>
            </div>
            <div class="option-item">
              <input type="checkbox" id="opt-links" checked />
              <label for="opt-links">保留链接</label>
            </div>
            <div class="option-item">
              <input type="checkbox" id="opt-images" checked />
              <label for="opt-images">包含图片</label>
            </div>
            <div class="option-item">
              <input type="checkbox" id="opt-formatting" checked />
              <label for="opt-formatting">保留格式</label>
            </div>
            <div class="option-item">
              <input type="checkbox" id="opt-fast" />
              <label for="opt-fast">快速模式</label>
            </div>
            <div class="option-item">
              <input type="checkbox" id="opt-dedup" />
              <label for="opt-dedup">去重检测</label>
            </div>
          </div>

          <div class="button-group">
            <button class="btn-primary" onclick="extractContent()">
              🚀 开始提取
            </button>
            <button class="btn-secondary" onclick="clearAll()">🗑️ 清除</button>
          </div>
        </div>

        <!-- Output Panel -->
        <div class="panel">
          <h2 class="panel-title">📤 提取结果</h2>

          <div class="stats">
            <div class="stat-card">
              <div class="label">提取时间</div>
              <div class="value" id="extractTime">-</div>
            </div>
            <div class="stat-card">
              <div class="label">内容长度</div>
              <div class="value" id="contentLength">-</div>
            </div>
            <div class="stat-card">
              <div class="label">质量评分</div>
              <div class="value" id="qualityScore">-</div>
            </div>
          </div>

          <div class="result-area">
            <div class="result-tabs">
              <button class="tab active" onclick="switchTab('content')">
                内容
              </button>
              <button class="tab" onclick="switchTab('metadata')">
                元数据
              </button>
              <button class="tab" onclick="switchTab('raw')">原始输出</button>
            </div>

            <div id="tab-content" class="tab-content active">
              <pre id="contentOutput">等待提取...</pre>
            </div>

            <div id="tab-metadata" class="tab-content">
              <div class="metadata-grid" id="metadataOutput">
                <div class="metadata-item">
                  <div class="key">等待提取...</div>
                </div>
              </div>
            </div>

            <div id="tab-raw" class="tab-content">
              <pre id="rawOutput">等待提取...</pre>
            </div>
          </div>
        </div>

        <!-- Log Panel -->
        <div class="panel log-panel">
          <h2 class="panel-title">📋 执行日志</h2>
          <div class="log-content" id="logContent">
            <div class="log-entry info">[INFO] 系统已准备就绪</div>
          </div>
        </div>
      </div>
    </div>

    <!-- Load Trafilatura Library -->
    <script src="dist/trafilatura.browser.js"></script>

    <script>
      // 测试样例数据
      const samples = {
        news: `<!DOCTYPE html>
<html lang="zh-CN">
<head>
<meta charset="UTF-8">
<meta property="og:title" content="人工智能新突破：GPT-4发布">
<meta property="og:description" content="OpenAI发布最新语言模型GPT-4，在多项任务上超越人类表现">
<meta property="article:published_time" content="2023-03-15T10:30:00Z">
<meta property="article:author" content="张三">
<title>人工智能新突破：GPT-4发布 - 科技日报</title>
</head>
<body>
<header class="site-header">
<nav>
  <a href="/">首页</a>
  <a href="/tech">科技</a>
  <a href="/about">关于</a>
</nav>
</header>

<article>
<h1>人工智能新突破：GPT-4发布</h1>
<div class="meta">
  <span class="author">作者：张三</span>
  <span class="date">2023-03-15</span>
</div>

<div class="content">
  <figure>
    <img src="https://example.com/gpt4-logo.png" alt="GPT-4 Logo" title="OpenAI GPT-4">
    <figcaption>GPT-4官方标志</figcaption>
  </figure>
  
  <p>3月15日，OpenAI正式发布了最新的大型语言模型GPT-4。这是继GPT-3之后的重大升级，在多项基准测试中展现出超越人类平均水平的能力。</p>
  
  <h2>主要特性</h2>
  <p>GPT-4具有以下突出特点：</p>
  <ul>
    <li>支持更长的上下文窗口，最高可达32,768个token</li>
    <li>在专业和学术考试中表现优异</li>
    <li>多模态能力，可以处理图像输入</li>
    <li>更强的推理和创造性能力</li>
  </ul>
  
  <h2>应用前景</h2>
  <img src="/images/gpt4-applications.jpg" alt="GPT-4应用场景" data-src="/images/gpt4-apps-hd.jpg">
  <p>专家认为，GPT-4将在教育、医疗、法律等多个领域带来革命性变化。它能够理解复杂的指令，生成高质量的内容，并在专业领域提供有价值的建议。</p>
  
  <table>
    <thead>
      <tr>
        <th>测试项目</th>
        <th>GPT-4分数</th>
        <th>人类平均分</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>SAT</td>
        <td>1410/1600</td>
        <td>1050/1600</td>
      </tr>
      <tr>
        <td>GRE</td>
        <td>163/170</td>
        <td>150/170</td>
      </tr>
    </tbody>
  </table>
  
  <blockquote>
    "GPT-4代表了人工智能发展的新里程碑，它的能力已经接近甚至超越了许多专业人士。" - OpenAI CEO Sam Altman
  </blockquote>
  
  <p>然而，OpenAI也警告称，GPT-4仍然存在幻觉、偏见等问题，需要在实际应用中谨慎使用。</p>
</div>

<div class="comments">
  <h3>评论</h3>
  <div class="comment">
    <p class="comment-author">李四</p>
    <p class="comment-text">太令人兴奋了！期待在教育领域的应用。</p>
  </div>
  <div class="comment">
    <p class="comment-author">王五</p>
    <p class="comment-text">技术进步太快了，需要重视AI安全问题。</p>
  </div>
</div>
</article>

<footer>
<p>© 2023 科技日报 版权所有</p>
</footer>
</body>
</html>`,

        blog: `<!DOCTYPE html>
<html>
<head>
<title>我的前端学习之旅 | 个人博客</title>
<meta name="description" content="分享我从零开始学习前端开发的经验">
<meta name="author" content="小明">
</head>
<body>
<article>
<h1>我的前端学习之旅</h1>
<p>作为一个编程新手，我想分享一下这半年来学习前端开发的心得体会。</p>

<h2>从HTML/CSS开始</h2>
<p>刚开始的时候，我连HTML标签都不认识。通过W3School和MDN的教程，我慢慢掌握了基础知识。</p>

<h2>JavaScript的挑战</h2>
<p>JavaScript相比HTML/CSS要难很多，特别是异步编程和闭包的概念。我花了整整一个月才真正理解Promise。</p>

<h2>框架的选择</h2>
<p>在React、Vue和Angular之间，我最终选择了Vue，因为它的学习曲线比较平缓。</p>

<p>现在，我已经能够独立开发一些小项目了。虽然还有很多要学，但我相信坚持就会有收获！</p>
</article>
</body>
</html>`,

        tech: `<!DOCTYPE html>
<html>
<head>
<title>JavaScript异步编程指南</title>
</head>
<body>
<article>
<h1>JavaScript异步编程指南</h1>

<h2>什么是异步编程</h2>
<p>异步编程是一种编程范式，允许程序在等待某个操作完成时继续执行其他任务。</p>

<h2>回调函数</h2>
<pre><code>
function fetchData(callback) {
setTimeout(() => {
callback('Data loaded');
}, 1000);
}
</code></pre>

<h2>Promise</h2>
<p>Promise提供了更优雅的异步处理方式：</p>
<pre><code>
const promise = new Promise((resolve, reject) => {
// 异步操作
});
</code></pre>

<h2>Async/Await</h2>
<p>这是最现代的异步编程语法，基于Promise。</p>
</article>
</body>
</html>`,

        chinese: `<!DOCTYPE html>
<html lang="zh-CN">
<head>
<title>中国古代四大发明</title>
</head>
<body>
<article>
<h1>中国古代四大发明</h1>
<p>中国古代四大发明是指造纸术、指南针、火药和印刷术，这些发明对世界文明的发展产生了深远影响。</p>

<h2>造纸术</h2>
<p>东汉时期，蔡伦改进了造纸技术，使纸张成为最主要的书写材料。</p>

<h2>指南针</h2>
<p>最早的指南针叫做司南，用于占卜，后来用于航海，促进了世界贸易的发展。</p>

<h2>火药</h2>
<p>火药最初用于炼丹，后来发展成为军事武器，改变了战争的形态。</p>

<h2>印刷术</h2>
<p>北宋时期，毕昇发明了活字印刷术，大大提高了书籍的传播效率。</p>
</article>
</body>
</html>`,
        complex: `<!DOCTYPE html>
<html lang="zh-CN">
<head>
<meta charset="UTF-8">
<title>深度解析：区块链技术的未来 - 科技观察</title>
<meta name="description" content="区块链技术正在改变世界，本文深入探讨其技术原理、应用场景和未来发展趋势">
<meta name="author" content="李明">
<meta name="keywords" content="区块链,加密货币,分布式账本,智能合约">
<meta property="og:title" content="深度解析：区块链技术的未来">
<meta property="og:type" content="article">
<meta property="og:url" content="https://tech-observer.com/articles/blockchain-future">
<meta property="article:published_time" content="2024-01-20T09:00:00Z">
<meta property="article:section" content="Technology">
<meta property="article:tag" content="区块链">
<meta property="article:tag" content="技术">
</head>
<body>
<!-- 顶部导航 -->
<header class="site-header">
<nav class="main-nav">
  <a href="/">首页</a>
  <a href="/tech">科技</a>
  <a href="/business">商业</a>
  <a href="/finance">金融</a>
  <a href="/about">关于我们</a>
</nav>
<div class="header-ads">
  <div class="ad-banner">广告位招租</div>
</div>
</header>

<div class="container">
<!-- 侧边栏 -->
<aside class="sidebar">
  <div class="widget hot-articles">
    <h3>热门文章</h3>
    <ul>
      <li><a href="/hot1">AI将如何改变未来</a></li>
      <li><a href="/hot2">量子计算机突破</a></li>
      <li><a href="/hot3">元宇宙的商业前景</a></li>
    </ul>
  </div>
  <div class="widget subscribe">
    <h3>订阅我们</h3>
    <form>
      <input type="email" placeholder="输入邮箱">
      <button>订阅</button>
    </form>
  </div>
  <div class="ad-sidebar">
    <img src="/ads/side-ad.jpg" alt="广告">
  </div>
</aside>

<!-- 主要内容 -->
<main class="main-content">
  <article>
    <header class="article-header">
      <h1>深度解析：区块链技术的未来</h1>
      <div class="article-meta">
        <span class="author">作者：李明</span>
        <span class="date">2024年1月20日</span>
        <span class="category">技术</span>
        <span class="read-time">阅读时间：10分钟</span>
      </div>
      <div class="social-share">
        <button>分享到微信</button>
        <button>分享到微博</button>
        <button>分享到Twitter</button>
      </div>
    </header>

    <div class="article-content">
      <p class="lead">区块链技术自2008年随比特币诞生以来，已经走过了15年的发展历程。从最初的加密货币应用，到如今在金融、供应链、医疗等多个领域的广泛应用，区块链正在深刻改变着我们的世界。</p>

      <div class="ad-inline">
        <div class="ad-content">【广告】了解更多区块链课程</div>
      </div>

      <h2>一、区块链的核心技术原理</h2>
      <p>区块链本质上是一种分布式账本技术（DLT），它通过密码学方法将数据区块按时间顺序链接成链，并通过共识机制确保数据的不可篡改性。</p>

      <h3>1.1 分布式账本</h3>
      <p>与传统的中心化数据库不同，区块链将数据分布存储在网络中的多个节点上。每个节点都保存着完整的账本副本，这使得系统具有极高的可靠性和抗攻击能力。</p>

      <div class="info-box">
        <h4>技术要点</h4>
        <ul>
          <li><strong>去中心化</strong>：没有单一的控制点</li>
          <li><strong>透明性</strong>：所有交易记录公开可查</li>
          <li><strong>不可篡改</strong>：历史记录无法修改</li>
          <li><strong>匿名性</strong>：用户身份受到保护</li>
        </ul>
      </div>

      <h3>1.2 共识机制</h3>
      <p>共识机制是区块链网络中节点就新区块达成一致的算法。常见的共识机制包括：</p>
      
      <table class="comparison-table">
        <thead>
          <tr>
            <th>共识机制</th>
            <th>代表项目</th>
            <th>优点</th>
            <th>缺点</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>PoW（工作量证明）</td>
            <td>比特币</td>
            <td>安全性高</td>
            <td>能耗大</td>
          </tr>
          <tr>
            <td>PoS（权益证明）</td>
            <td>以太坊2.0</td>
            <td>节能环保</td>
            <td>可能导致中心化</td>
          </tr>
          <tr>
            <td>DPoS（委托权益证明）</td>
            <td>EOS</td>
            <td>交易速度快</td>
            <td>去中心化程度低</td>
          </tr>
        </tbody>
      </table>

      <div class="ad-inline">
        <div class="ad-content">【广告】投资区块链项目，年化收益20%</div>
      </div>

      <h2>二、区块链的应用场景</h2>
      
      <h3>2.1 金融领域</h3>
      <p>区块链在金融领域的应用最为成熟。从跨境支付到证券交易，从供应链金融到数字身份认证，区块链正在重塑传统金融服务。</p>

      <blockquote class="expert-quote">
        "区块链技术将彻底改变金融行业的运作方式，它不仅能大幅降低交易成本，还能提高系统的透明度和安全性。" <cite>— 国际货币基金组织总裁</cite>
      </blockquote>

      <h3>2.2 供应链管理</h3>
      <p>通过区块链技术，企业可以实现供应链的全程追溯。从原材料采购到产品交付，每一个环节都被记录在链上，确保产品的真实性和质量。</p>

      <div class="case-study">
        <h4>案例：某奢侈品牌的防伪应用</h4>
        <p>该品牌将每件产品的信息上链，消费者通过扫描二维码即可验证产品真伪，有效打击了假冒伪劣产品。上线半年后，假货投诉率下降了85%。</p>
      </div>

      <h3>2.3 数字身份</h3>
      <p>区块链可以为每个人创建一个去中心化的数字身份，用户完全掌控自己的身份数据，既保护了隐私，又方便了跨平台认证。</p>

      <h2>三、技术挑战与未来展望</h2>

      <h3>3.1 当前面临的挑战</h3>
      <ol>
        <li><strong>性能瓶颈</strong>：当前主流公链的TPS（每秒交易数）仍然较低</li>
        <li><strong>能耗问题</strong>：PoW机制消耗大量电力</li>
        <li><strong>监管缺失</strong>：法律法规尚不完善</li>
        <li><strong>互操作性</strong>：不同区块链之间难以互通</li>
        <li><strong>用户体验</strong>：对普通用户仍然不够友好</li>
      </ol>

      <h3>3.2 未来发展趋势</h3>
      <p>展望未来，区块链技术将朝着以下方向发展：</p>

      <ul>
        <li><strong>Layer 2解决方案</strong>：通过闪电网络、状态通道等技术提升性能</li>
        <li><strong>跨链技术</strong>：实现不同区块链之间的互联互通</li>
        <li><strong>隐私保护</strong>：零知识证明等技术保护用户隐私</li>
        <li><strong>与AI结合</strong>：智能合约更加智能化</li>
        <li><strong>监管科技</strong>：合规化发展趋势明显</li>
      </ul>

      <div class="future-vision">
        <h4>2030年展望</h4>
        <p>到2030年，预计全球将有30%的企业采用区块链技术，市场规模将达到3.1万亿美元。区块链将成为数字经济的基础设施，就像今天的互联网一样不可或缺。</p>
      </div>

      <h2>四、结论</h2>
      <p>区块链技术正处在快速发展阶段，虽然仍面临诸多挑战，但其巨大的潜力不容忽视。随着技术的不断成熟和应用场景的不断拓展，区块链必将在未来的数字经济中扮演越来越重要的角色。</p>

      <p>作为技术从业者和投资者，我们应该以开放的心态拥抱这项新技术，同时也要保持理性，警惕各种打着区块链旗号的骗局。只有真正理解区块链的本质，才能在这场技术革命中把握机遇。</p>
    </div>

    <!-- 文章底部 -->
    <footer class="article-footer">
      <div class="tags">
        <span>标签：</span>
        <a href="/tag/blockchain">区块链</a>
        <a href="/tag/technology">技术</a>
        <a href="/tag/future">未来</a>
        <a href="/tag/fintech">金融科技</a>
      </div>
      <div class="author-bio">
        <img src="/authors/liming.jpg" alt="李明">
        <div>
          <h4>关于作者：李明</h4>
          <p>资深区块链技术专家，10年行业经验，曾参与多个大型区块链项目的设计与实施。</p>
        </div>
      </div>
    </footer>

    <!-- 评论区 -->
    <section class="comments-section">
      <h3>读者评论 (128)</h3>
      <div class="comment">
        <div class="comment-author">张伟</div>
        <div class="comment-text">文章写得非常深入浅出，对区块链技术的解析很到位！特别是共识机制那部分，讲得很清楚。</div>
        <div class="comment-meta">2024-01-20 10:30</div>
      </div>
      <div class="comment">
        <div class="comment-author">王芳</div>
        <div class="comment-text">区块链确实是未来趋势，但我觉得当前的应用场景还是太少了，期待看到更多实际落地的案例。</div>
        <div class="comment-meta">2024-01-20 11:15</div>
      </div>
      <div class="comment">
        <div class="comment-author">赵强</div>
        <div class="comment-text">技术细节讲得很好，但对于普通读者来说可能还是有点深奥。建议可以增加更多图解。</div>
        <div class="comment-meta">2024-01-20 14:22</div>
      </div>
    </section>
  </article>

  <!-- 相关文章推荐 -->
  <section class="related-articles">
    <h3>相关推荐</h3>
    <div class="article-grid">
      <div class="article-card">
        <img src="/thumb1.jpg" alt="">
        <h4>比特币的下一个十年</h4>
        <p>加密货币市场分析...</p>
      </div>
      <div class="article-card">
        <img src="/thumb2.jpg" alt="">
        <h4>以太坊2.0技术解析</h4>
        <p>PoS共识机制详解...</p>
      </div>
      <div class="article-card">
        <img src="/thumb3.jpg" alt="">
        <h4>NFT艺术品市场观察</h4>
        <p>数字藏品的投资价值...</p>
      </div>
    </div>
  </section>
</main>
</div>

<!-- 页脚 -->
<footer class="site-footer">
<div class="footer-content">
  <div class="footer-section">
    <h4>关于我们</h4>
    <p>科技观察是专业的科技资讯平台</p>
  </div>
  <div class="footer-section">
    <h4>联系方式</h4>
    <p>邮箱：contact@tech-observer.com</p>
  </div>
  <div class="footer-section">
    <h4>关注我们</h4>
    <div class="social-links">
      <a href="#">微信</a>
      <a href="#">微博</a>
      <a href="#">Twitter</a>
    </div>
  </div>
</div>
<div class="copyright">
  <p>© 2024 科技观察 版权所有 | ICP备案号：京ICP备12345678号</p>
</div>
</footer>
</body>
</html>`,

        ecommerce: `<!DOCTYPE html>
<html lang="zh-CN">

<body>
<div class="product-page">
<nav class="breadcrumb">
  <a href="/">首页</a> &gt;
  <a href="/electronics">数码产品</a> &gt;
  <a href="/phones">手机</a> &gt;
  <span>iPhone 15 Pro Max</span>
</nav>

<div class="product-main">
  <div class="product-gallery">
    <img src="/products/iphone15pro-1.jpg" alt="iPhone 15 Pro Max正面">
    <div class="gallery-thumbs">
      <img src="/products/iphone15pro-2.jpg" alt="侧面">
      <img src="/products/iphone15pro-3.jpg" alt="背面">
      <img src="/products/iphone15pro-4.jpg" alt="相机">
    </div>
  </div>

  <div class="product-info">
    <h1>Apple iPhone 15 Pro Max</h1>
    <p class="product-subtitle">钛金属设计 | A17 Pro芯片 | Pro级相机系统</p>

    <div class="price-section">
      <div class="current-price">¥9,999</div>
      <div class="original-price">¥10,999</div>
      <div class="discount-badge">限时优惠</div>
    </div>

    <div class="rating">
      <span class="stars">★★★★★</span>
      <span class="rating-score">4.8分</span>
      <a href="#reviews">1523条评价</a>
    </div>

    <div class="product-options">
      <div class="option-group">
        <label>颜色：</label>
        <div class="color-options">
          <button class="color-option selected" data-color="black">深空黑</button>
          <button class="color-option" data-color="silver">银色</button>
          <button class="color-option" data-color="gold">金色</button>
          <button class="color-option" data-color="blue">蓝色钛金属</button>
        </div>
      </div>

      <div class="option-group">
        <label>容量：</label>
        <div class="storage-options">
          <button class="storage-option">128GB - ¥9,499</button>
          <button class="storage-option selected">256GB - ¥9,999</button>
          <button class="storage-option">512GB - ¥11,499</button>
          <button class="storage-option">1TB - ¥13,499</button>
        </div>
      </div>
    </div>

    <div class="stock-info">
      <span class="in-stock">有货</span>
      <span>预计3-5天送达</span>
    </div>

    <div class="purchase-actions">
      <button class="btn-buy-now">立即购买</button>
      <button class="btn-add-cart">加入购物车</button>
      <button class="btn-wishlist">♥ 收藏</button>
    </div>

    <div class="service-promises">
      <div class="promise-item">✓ 7天无理由退货</div>
      <div class="promise-item">✓ 全国联保</div>
      <div class="promise-item">✓ 官方正品保证</div>
      <div class="promise-item">✓ 免费配送</div>
    </div>
  </div>
</div>

<div class="product-details">
  <div class="tabs">
    <button class="tab active">产品详情</button>
    <button class="tab">规格参数</button>
    <button class="tab">用户评价</button>
  </div>

  <div class="tab-content active">
    <h2>产品亮点</h2>
    
    <h3>钛金属设计，轻盈坚固</h3>
    <p>iPhone 15 Pro Max采用航空级钛金属打造，是迄今最轻的Pro系列机型。钛金属具有出色的强度重量比，让手机更加坚固耐用的同时，重量比不锈钢轻约19克。</p>

    <h3>A17 Pro芯片，性能飞跃</h3>
    <p>全新的A17 Pro芯片采用3纳米工艺制程，拥有6核CPU和6核GPU，性能提升高达20%。无论是玩大型游戏还是处理复杂任务，都能流畅应对。</p>

    <h3>Pro级相机系统</h3>
    <ul>
      <li><strong>4800万像素主摄</strong>：支持第二代传感器位移式光学图像防抖</li>
      <li><strong>5倍光学变焦</strong>：采用四棱镜潜望式长焦设计</li>
      <li><strong>超广角镜头</strong>：1200万像素，支持微距摄影</li>
      <li><strong>人像模式2.0</strong>：自动识别主体，拍摄更专业的人像照片</li>
    </ul>

    <h3>全天候电池续航</h3>
    <p>配备更大容量电池和优化的电源管理系统，视频播放时间长达29小时。支持MagSafe无线充电和20W快速充电。</p>

    <h3>动作按钮</h3>
    <p>全新的动作按钮取代了传统的静音开关，可自定义快速启动相机、录音、手电筒等功能，让操作更加便捷。</p>

    <h2>技术规格</h2>
    <table class="specs-table">
      <tr>
        <td>显示屏</td>
        <td>6.7英寸超视网膜XDR显示屏，2796 x 1290像素，460ppi，ProMotion自适应刷新率</td>
      </tr>
      <tr>
        <td>芯片</td>
        <td>A17 Pro芯片，6核CPU，6核GPU，16核神经网络引擎</td>
      </tr>
      <tr>
        <td>存储容量</td>
        <td>256GB</td>
      </tr>
      <tr>
        <td>相机系统</td>
        <td>4800万像素主摄 + 1200万像素超广角 + 1200万像素5倍长焦</td>
      </tr>
      <tr>
        <td>电池</td>
        <td>视频播放最长可达29小时</td>
      </tr>
      <tr>
        <td>防护</td>
        <td>IP68级别防尘防水</td>
      </tr>
      <tr>
        <td>重量</td>
        <td>221克</td>
      </tr>
    </table>

    <h2>包装内容</h2>
    <ul>
      <li>iPhone 15 Pro Max</li>
      <li>USB-C转USB-C编织充电线</li>
      <li>使用手册</li>
      <li>Apple贴纸</li>
    </ul>
  </div>
</div>

<div class="reviews-section" id="reviews">
  <h2>用户评价 (1523条)</h2>
  <div class="rating-summary">
    <div class="overall-rating">
      <div class="rating-score">4.8</div>
      <div class="rating-stars">★★★★★</div>
      <div class="rating-count">基于1523条评价</div>
    </div>
    <div class="rating-distribution">
      <div class="rating-bar">
        <span>5星</span>
        <div class="bar"><div class="fill" style="width: 78%"></div></div>
        <span>78%</span>
      </div>
      <div class="rating-bar">
        <span>4星</span>
        <div class="bar"><div class="fill" style="width: 15%"></div></div>
        <span>15%</span>
      </div>
      <div class="rating-bar">
        <span>3星</span>
        <div class="bar"><div class="fill" style="width: 5%"></div></div>
        <span>5%</span>
      </div>
      <div class="rating-bar">
        <span>2星</span>
        <div class="bar"><div class="fill" style="width: 1%"></div></div>
        <span>1%</span>
      </div>
      <div class="rating-bar">
        <span>1星</span>
        <div class="bar"><div class="fill" style="width: 1%"></div></div>
        <span>1%</span>
      </div>
    </div>
  </div>

  <div class="review-list">
    <div class="review-item">
      <div class="reviewer-info">
        <span class="reviewer-name">科技达人小王</span>
        <span class="review-rating">★★★★★</span>
        <span class="review-date">2024-01-15</span>
      </div>
      <div class="review-content">
        <p class="review-title">物超所值的旗舰机</p>
        <p>使用了一周，整体感受非常好。钛金属机身手感出色，重量比上一代轻了不少。A17 Pro芯片性能强劲，玩《原神》全特效也不卡。相机系统尤其出色，5倍长焦很实用，拍人像效果堪比单反。电池续航也有明显提升，一天重度使用下来还有20%的电量。唯一的缺点是价格有点贵，但考虑到这是旗舰机，还是值得的。</p>
      </div>
    </div>

    <div class="review-item">
      <div class="reviewer-info">
        <span class="reviewer-name">摄影爱好者李华</span>
        <span class="review-rating">★★★★★</span>
        <span class="review-date">2024-01-10</span>
      </div>
      <div class="review-content">
        <p class="review-title">相机系统太棒了</p>
        <p>作为一名业余摄影师，我对手机相机要求很高。iPhone 15 Pro Max的相机系统完全超出了我的预期。4800万像素主摄拍摄的照片细节丰富，5倍光学变焦让我能拍到更多画面。新的人像模式非常智能，自动识别主体后能产生专业级的虚化效果。夜景模式也有显著提升，暗光环境下也能拍出清晰的照片。强烈推荐给喜欢摄影的朋友！</p>
      </div>
    </div>
  </div>
</div>
</div>
</body>
</html>`,

        recipe: `<!DOCTYPE html>
<html lang="zh-CN">

<body>
<article class="recipe">
<header>
  <h1>宫保鸡丁的正宗做法</h1>
  <div class="recipe-meta">
    <span class="author">作者：大厨张师傅</span>
    <span class="date">2024年1月18日</span>
    <span class="difficulty">难度：中等</span>
    <span class="time">总时长：30分钟</span>
  </div>
  <div class="recipe-rating">
    <span class="stars">★★★★★</span>
    <span>4.9分 (328人评价)</span>
  </div>
</header>

<div class="recipe-summary">
  <img src="/recipes/gongbaojiding.jpg" alt="宫保鸡丁成品图" class="recipe-image">
  <div class="summary-text">
    <p>宫保鸡丁是一道经典的川菜，以鸡肉、花生米、干辣椒等为主料烹制而成。成菜色泽红亮，鸡肉鲜嫩，花生酥脆，口味鲜辣酸甜，令人回味无穷。</p>
    <div class="quick-info">
      <div class="info-item">
        <strong>准备时间</strong>
        <span>20分钟</span>
      </div>
      <div class="info-item">
        <strong>烹饪时间</strong>
        <span>10分钟</span>
      </div>
      <div class="info-item">
        <strong>份量</strong>
        <span>2-3人份</span>
      </div>
      <div class="info-item">
        <strong>热量</strong>
        <span>约350卡/份</span>
      </div>
    </div>
  </div>
</div>

<section class="ingredients">
  <h2>所需食材</h2>
  
  <h3>主料</h3>
  <ul>
    <li><input type="checkbox"> 鸡胸肉 300克</li>
    <li><input type="checkbox"> 干辣椒 10-15个</li>
    <li><input type="checkbox"> 花椒 1小勺</li>
    <li><input type="checkbox"> 花生米 50克（炸熟或烤熟）</li>
    <li><input type="checkbox"> 大葱白 1段</li>
    <li><input type="checkbox"> 姜 10克</li>
    <li><input type="checkbox"> 蒜 3瓣</li>
  </ul>

  <h3>腌料</h3>
  <ul>
    <li><input type="checkbox"> 料酒 1勺</li>
    <li><input type="checkbox"> 生抽 1勺</li>
    <li><input type="checkbox"> 淀粉 1勺</li>
    <li><input type="checkbox"> 盐 少许</li>
  </ul>

  <h3>调味料</h3>
  <ul>
    <li><input type="checkbox"> 白糖 1勺</li>
    <li><input type="checkbox"> 香醋 1勺</li>
    <li><input type="checkbox"> 生抽 2勺</li>
    <li><input type="checkbox"> 老抽 半勺（上色用）</li>
    <li><input type="checkbox"> 水淀粉 2勺</li>
    <li><input type="checkbox"> 鸡精 少许</li>
  </ul>
</section>

<section class="instructions">
  <h2>制作步骤</h2>

  <div class="step">
    <div class="step-number">步骤 1</div>
    <div class="step-content">
      <h3>准备食材</h3>
      <p>将鸡胸肉洗净后切成1.5cm左右的小丁，放入碗中。加入料酒、生抽、淀粉和少许盐，抓匀腌制15-20分钟，让鸡肉充分入味。</p>
      <p class="tip">💡 <strong>技巧</strong>：鸡肉切丁时要逆纹理切，这样口感更嫩。腌制时加入淀粉可以锁住水分，让鸡肉更滑嫩。</p>
    </div>
  </div>

  <div class="step">
    <div class="step-number">步骤 2</div>
    <div class="step-content">
      <h3>处理配料</h3>
      <ul>
        <li>干辣椒用剪刀剪成小段，去掉辣椒籽（喜欢更辣可以保留）</li>
        <li>大葱白切成小段</li>
        <li>姜切末</li>
        <li>蒜切片</li>
        <li>花生米如果是生的，需要提前炸熟或烤熟</li>
      </ul>
    </div>
  </div>

  <div class="step">
    <div class="step-number">步骤 3</div>
    <div class="step-content">
      <h3>调制宫保汁</h3>
      <p>在小碗中调制宫保汁：白糖1勺、香醋1勺、生抽2勺、老抽半勺、水淀粉2勺、鸡精少许，加入2勺清水混合均匀备用。</p>
      <p class="tip">💡 <strong>技巧</strong>：宫保汁的灵魂在于糖醋比例，基本是1:1，可以根据个人口味微调。提前调好汁可以避免炒菜时手忙脚乱。</p>
    </div>
  </div>

  <div class="step">
    <div class="step-number">步骤 4</div>
    <div class="step-content">
      <h3>炒制鸡丁</h3>
      <ol>
        <li>锅中倒入适量油，油温五成热时（约150°C），放入腌好的鸡丁</li>
        <li>快速滑炒至鸡肉变色，约七八成熟时盛出备用</li>
        <li>这一步主要是给鸡肉定型和初步断生</li>
      </ol>
      <p class="warning">⚠️ <strong>注意</strong>：油温不要太高，否则鸡肉外面老了里面还没熟。鸡肉变色就要立即盛出，避免炒老。</p>
    </div>
  </div>

  <div class="step">
    <div class="step-number">步骤 5</div>
    <div class="step-content">
      <h3>爆香调料</h3>
      <ol>
        <li>锅留底油，放入花椒小火慢炒出香味</li>
        <li>加入干辣椒段，炒至辣椒颜色微变</li>
        <li>放入葱姜蒜爆香</li>
      </ol>
      <p class="tip">💡 <strong>技巧</strong>：花椒一定要小火慢炒，火大了容易糊，会有苦味。辣椒炒到颜色微变就可以了，不要炒黑。</p>
    </div>
  </div>

  <div class="step">
    <div class="step-number">步骤 6</div>
    <div class="step-content">
      <h3>快速翻炒</h3>
      <ol>
        <li>倒入滑好的鸡丁，大火快速翻炒均匀</li>
        <li>倒入提前调好的宫保汁</li>
        <li>继续大火快炒，让汁液均匀裹在鸡丁上</li>
        <li>加入花生米，快速翻炒几下</li>
      </ol>
      <p class="tip">💡 <strong>技巧</strong>：这一步要大火快炒，动作要快，整个过程不超过1分钟。汁液收浓即可出锅，不要炒干。</p>
    </div>
  </div>

  <div class="step">
    <div class="step-number">步骤 7</div>
    <div class="step-content">
      <h3>出锅装盘</h3>
      <p>看到汁液浓稠、包裹在鸡丁上呈现诱人的红亮色泽时，立即关火出锅装盘。一道正宗的宫保鸡丁就完成了！</p>
    </div>
  </div>
</section>

<section class="tips">
  <h2>烹饪技巧</h2>
  <ol>
    <li><strong>鸡肉的选择与处理</strong>：首选鸡胸肉，肉质紧实。也可以用鸡腿肉，口感更嫩但油脂稍多。切丁要均匀，大小一致才能受热均匀。</li>
    <li><strong>火候控制</strong>：炒鸡丁用中火，爆香用小火，最后翻炒用大火。掌握好火候是这道菜的关键。</li>
    <li><strong>调味平衡</strong>：宫保鸡丁讲究酸甜咸辣香五味调和，糖醋比例是关键，可以先少放，边尝边调整。</li>
    <li><strong>花生米的处理</strong>：花生米最后加入，保持酥脆口感。如果提前加会吸收汤汁变软。</li>
    <li><strong>水淀粉的用量</strong>：不要加太多，薄薄一层包裹即可。加多了汁水会太稠，影响口感。</li>
  </ol>
</section>

<section class="nutrition">
  <h2>营养价值</h2>
  <table>
    <tr>
      <th>营养成分</th>
      <th>每份含量</th>
      <th>占每日推荐量</th>
    </tr>
    <tr>
      <td>热量</td>
      <td>350 kcal</td>
      <td>17%</td>
    </tr>
    <tr>
      <td>蛋白质</td>
      <td>30g</td>
      <td>60%</td>
    </tr>
    <tr>
      <td>碳水化合物</td>
      <td>18g</td>
      <td>6%</td>
    </tr>
    <tr>
      <td>脂肪</td>
      <td>18g</td>
      <td>28%</td>
    </tr>
    <tr>
      <td>膳食纤维</td>
      <td>3g</td>
      <td>12%</td>
    </tr>
    <tr>
      <td>钠</td>
      <td>800mg</td>
      <td>33%</td>
    </tr>
  </table>
  <p class="nutrition-note">营养数据基于标准食谱计算，实际数值可能因食材用量而有所不同。</p>
</section>

<section class="comments">
  <h2>用户评价与分享</h2>
  
  <div class="comment">
    <div class="comment-header">
      <span class="user-name">美食爱好者小李</span>
      <span class="rating">★★★★★</span>
      <span class="date">2024-01-20</span>
    </div>
    <p>按照这个菜谱做出来的宫保鸡丁太棒了！和餐馆的味道一模一样。特别是调味汁的配比很准确，酸甜适中。我家孩子特别爱吃，一盘都不够。感谢张师傅的详细教程！</p>
  </div>

  <div class="comment">
    <div class="comment-header">
      <span class="user-name">厨房新手王芳</span>
      <span class="rating">★★★★★</span>
      <span class="date">2024-01-18</span>
    </div>
    <p>作为一个厨房新手，我第一次尝试做川菜就选了宫保鸡丁。菜谱写得非常详细，每一步都有技巧提示，很贴心。虽然第一次做火候掌握得不太好，鸡肉有点老，但味道还是很不错的。下次再试会更好！</p>
  </div>
</section>
</article>
</body>
</html>`,

        research: `<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Deep Learning Approaches for Natural Language Processing: A Comprehensive Survey</title>
<meta name="description" content="A systematic review of deep learning methods applied to natural language processing tasks">
<meta name="author" content="Dr. Sarah Johnson, Prof. Michael Chen, Dr. Emily Zhang">
<meta name="keywords" content="deep learning, natural language processing, NLP, transformers, BERT, GPT">
<meta name="citation_title" content="Deep Learning Approaches for Natural Language Processing">
<meta name="citation_author" content="Johnson, Sarah">
<meta name="citation_author" content="Chen, Michael">
<meta name="citation_author" content="Zhang, Emily">
<meta name="citation_publication_date" content="2024/01/15">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_volume" content="72">
<meta name="citation_issue" content="1">
<meta name="citation_firstpage" content="45">
<meta name="citation_lastpage" content="98">
<meta name="citation_doi" content="10.1613/jair.2024.12345">
</head>
<body>
<article class="research-paper">
<header class="paper-header">
  <h1>Deep Learning Approaches for Natural Language Processing: A Comprehensive Survey</h1>
  
  <div class="authors">
    <div class="author">
      <span class="name">Sarah Johnson<sup>1,*</sup></span>
      <span class="affiliation">Department of Computer Science, Stanford University</span>
    </div>
    <div class="author">
      <span class="name">Michael Chen<sup>2</sup></span>
      <span class="affiliation">AI Research Lab, MIT</span>
    </div>
    <div class="author">
      <span class="name">Emily Zhang<sup>3</sup></span>
      <span class="affiliation">School of Information, UC Berkeley</span>
    </div>
  </div>

  <div class="paper-meta">
    <p><strong>Published:</strong> January 15, 2024</p>
    <p><strong>Journal:</strong> Journal of Artificial Intelligence Research, Vol. 72, Issue 1, pp. 45-98</p>
    <p><strong>DOI:</strong> <a href="https://doi.org/10.1613/jair.2024.12345">10.1613/jair.2024.12345</a></p>
    <p><strong>*Corresponding author:</strong> sjohnson@stanford.edu</p>
  </div>
</header>

<section class="abstract">
  <h2>Abstract</h2>
  <p>Natural Language Processing (NLP) has experienced remarkable progress in recent years, primarily driven by advances in deep learning. This comprehensive survey examines the evolution of deep learning architectures and their applications across various NLP tasks. We provide a systematic overview of foundational models, including Recurrent Neural Networks (RNNs), Long Short-Term Memory networks (LSTMs), and attention mechanisms, before delving into modern transformer-based architectures such as BERT, GPT, and T5.</p>
  
  <p>Our analysis covers key NLP tasks including machine translation, sentiment analysis, named entity recognition, question answering, and text generation. We discuss the strengths and limitations of different approaches, highlighting recent innovations in pre-training strategies, transfer learning, and few-shot learning paradigms. Special attention is given to the emergence of large language models (LLMs) and their impact on the field.</p>
  
  <p>Furthermore, we address critical challenges facing the NLP community, including computational efficiency, model interpretability, bias mitigation, and multilingual capabilities. We also explore emerging trends such as prompt engineering, in-context learning, and the integration of external knowledge bases. Our survey concludes with a discussion of future research directions and potential breakthroughs that may shape the next generation of NLP systems.</p>
  
  <p><strong>Keywords:</strong> Deep Learning, Natural Language Processing, Transformers, BERT, GPT, Large Language Models, Transfer Learning, Attention Mechanisms</p>
</section>

<section class="introduction">
  <h2>1. Introduction</h2>
  
  <p>Natural Language Processing (NLP) stands at the intersection of linguistics, computer science, and artificial intelligence, aiming to enable machines to understand, interpret, and generate human language. Over the past decade, the field has witnessed a paradigm shift from traditional rule-based and statistical methods to deep learning approaches, fundamentally transforming how we build and deploy NLP systems [1, 2].</p>

  <p>The success of deep learning in NLP can be attributed to several key factors: (1) the availability of large-scale text corpora, (2) advances in neural network architectures, particularly attention mechanisms and transformers, (3) the development of effective pre-training strategies, and (4) increased computational resources enabling the training of massive models [3, 4, 5].</p>

  <p>This survey provides a comprehensive analysis of deep learning approaches in NLP, organized as follows: Section 2 reviews foundational neural network architectures; Section 3 examines pre-training strategies and transfer learning; Section 4 discusses applications across various NLP tasks; Section 5 addresses current challenges and limitations; Section 6 explores emerging trends and future directions; and Section 7 concludes with key takeaways and recommendations for researchers and practitioners.</p>

  <h3>1.1 Motivation and Scope</h3>
  <p>While numerous surveys have been published on deep learning for NLP [6, 7, 8], the rapid pace of innovation necessitates regular updates to capture recent developments. This survey is distinctive in several ways:</p>
  
  <ul>
    <li>We provide updated coverage of the latest architectures and techniques, including GPT-4, LLaMA, and other recent large language models.</li>
    <li>We offer a balanced perspective on both the achievements and limitations of current approaches.</li>
    <li>We emphasize practical considerations for deploying NLP systems in real-world applications.</li>
    <li>We discuss emerging challenges such as model efficiency, environmental impact, and ethical considerations.</li>
  </ul>

  <h3>1.2 Historical Context</h3>
  <p>To appreciate the current state of deep learning in NLP, it is instructive to briefly review the field's evolution. Early NLP systems relied heavily on hand-crafted rules and linguistic knowledge bases [9]. The statistical NLP era, beginning in the 1990s, introduced machine learning methods such as Hidden Markov Models (HMMs) and Conditional Random Fields (CRFs) [10, 11].</p>

  <p>The deep learning revolution in NLP can be traced to several seminal works: word2vec's demonstration of effective word embeddings [12], the successful application of RNNs to sequence modeling [13], the introduction of attention mechanisms [14], and most significantly, the transformer architecture [15] that forms the foundation of modern NLP systems.</p>
</section>

<section class="related-work">
  <h2>2. Foundational Architectures</h2>

  <h3>2.1 Recurrent Neural Networks</h3>
  <p>Recurrent Neural Networks (RNNs) were among the first deep learning architectures successfully applied to NLP tasks. Unlike feedforward networks, RNNs maintain a hidden state that captures information from previous time steps, making them naturally suited for sequential data [16]. The hidden state h<sub>t</sub> at time t is computed as:</p>

  <div class="equation">
    <p>h<sub>t</sub> = tanh(W<sub>hh</sub>h<sub>t-1</sub> + W<sub>xh</sub>x<sub>t</sub> + b<sub>h</sub>)</p>
  </div>

  <p>Despite their theoretical appeal, vanilla RNNs suffer from the vanishing gradient problem, limiting their ability to capture long-range dependencies [17].</p>

  <h3>2.2 Long Short-Term Memory Networks</h3>
  <p>Long Short-Term Memory (LSTM) networks address the limitations of vanilla RNNs through a gating mechanism that regulates information flow [18]. The LSTM cell consists of three gates – input gate (i<sub>t</sub>), forget gate (f<sub>t</sub>), and output gate (o<sub>t</sub>) – and a cell state (c<sub>t</sub>) that serves as a memory component:</p>

  <div class="equations">
    <p>i<sub>t</sub> = σ(W<sub>i</sub>[h<sub>t-1</sub>, x<sub>t</sub>] + b<sub>i</sub>)</p>
    <p>f<sub>t</sub> = σ(W<sub>f</sub>[h<sub>t-1</sub>, x<sub>t</sub>] + b<sub>f</sub>)</p>
    <p>o<sub>t</sub> = σ(W<sub>o</sub>[h<sub>t-1</sub>, x<sub>t</sub>] + b<sub>o</sub>)</p>
    <p>c<sub>t</sub> = f<sub>t</sub> ⊙ c<sub>t-1</sub> + i<sub>t</sub> ⊙ tanh(W<sub>c</sub>[h<sub>t-1</sub>, x<sub>t</sub>] + b<sub>c</sub>)</p>
    <p>h<sub>t</sub> = o<sub>t</sub> ⊙ tanh(c<sub>t</sub>)</p>
  </div>

  <p>LSTMs have been successfully applied to various NLP tasks, including machine translation [19], language modeling [20], and text classification [21].</p>

  <h3>2.3 Attention Mechanisms</h3>
  <p>The introduction of attention mechanisms marked a significant milestone in NLP [14, 22]. Attention allows models to dynamically focus on relevant parts of the input sequence when generating each output token. Given a query q, keys K, and values V, the attention mechanism computes:</p>

  <div class="equation">
    <p>Attention(Q, K, V) = softmax(QK<sup>T</sup>/√d<sub>k</sub>)V</p>
  </div>

  <p>where d<sub>k</sub> is the dimensionality of the keys. This scaled dot-product attention forms the basis of modern transformer architectures.</p>

  <h3>2.4 Transformer Architecture</h3>
  <p>The transformer architecture, introduced by Vaswani et al. [15], revolutionized NLP by dispensing with recurrence entirely and relying solely on attention mechanisms. The key innovations include:</p>

  <ul>
    <li><strong>Multi-head attention:</strong> Multiple attention mechanisms operating in parallel, allowing the model to attend to different aspects of the input simultaneously.</li>
    <li><strong>Positional encoding:</strong> Injecting information about token positions since transformers lack inherent sequential structure.</li>
    <li><strong>Feed-forward networks:</strong> Position-wise fully connected layers applied to each position independently.</li>
    <li><strong>Layer normalization and residual connections:</strong> Facilitating training of deep networks.</li>
  </ul>

  <p>The transformer's ability to process sequences in parallel, combined with its effectiveness at capturing long-range dependencies, has made it the de facto standard for modern NLP systems.</p>
</section>

<section class="methods">
  <h2>3. Pre-training and Transfer Learning</h2>

  <h3>3.1 Word Embeddings</h3>
  <p>The concept of representing words as dense vectors learned from large text corpora laid the groundwork for modern pre-training approaches. Word2vec [12] and GloVe [23] demonstrated that semantic relationships could be captured through vector arithmetic, with famous examples such as "king - man + woman ≈ queen".</p>

  <h3>3.2 Contextualized Representations</h3>
  <p>Traditional word embeddings assign a single vector to each word regardless of context. ELMo (Embeddings from Language Models) [24] introduced contextualized representations by using bidirectional LSTMs trained on language modeling tasks. This approach captures polysemy and context-dependent meanings.</p>

  <h3>3.3 BERT and Bidirectional Pre-training</h3>
  <p>BERT (Bidirectional Encoder Representations from Transformers) [25] revolutionized NLP through its innovative pre-training strategy:</p>

  <ul>
    <li><strong>Masked Language Modeling (MLM):</strong> Randomly masking input tokens and training the model to predict them based on bidirectional context.</li>
    <li><strong>Next Sentence Prediction (NSP):</strong> Training the model to understand relationships between sentence pairs.</li>
  </ul>

  <p>BERT achieved state-of-the-art results across numerous NLP benchmarks and spawned numerous variants including RoBERTa [26], ALBERT [27], and DistilBERT [28].</p>

  <h3>3.4 Autoregressive Models: GPT Family</h3>
  <p>In contrast to BERT's bidirectional approach, the GPT (Generative Pre-trained Transformer) series [29, 30, 31] employs causal language modeling, predicting the next token given previous tokens. This autoregressive approach has proven highly effective for text generation tasks.</p>

  <p>The scaling of GPT models from GPT (117M parameters) to GPT-2 (1.5B parameters) to GPT-3 (175B parameters) and beyond has revealed emergent capabilities such as few-shot and zero-shot learning, where models can perform tasks they weren't explicitly trained for [31].</p>

  <h3>3.5 Encoder-Decoder Models</h3>
  <p>Models like T5 (Text-to-Text Transfer Transformer) [32] and BART [33] combine encoder and decoder components, treating every NLP task as a text-to-text problem. This unified framework simplifies model architecture and training procedures while achieving strong performance across diverse tasks.</p>
</section>

<section class="results">
  <h2>4. Applications and Performance</h2>

  <h3>4.1 Machine Translation</h3>
  <p>Neural machine translation (NMT) has benefited immensely from deep learning. Transformer-based models have largely replaced earlier RNN-based approaches, achieving near-human translation quality for high-resource language pairs [34]. However, challenges remain for low-resource languages and domain adaptation.</p>

  <table class="results-table">
    <caption>Table 1: BLEU scores on WMT'14 English-German translation task</caption>
    <thead>
      <tr>
        <th>Model</th>
        <th>Year</th>
        <th>BLEU Score</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>RNN with attention</td>
        <td>2015</td>
        <td>24.1</td>
      </tr>
      <tr>
        <td>Transformer (base)</td>
        <td>2017</td>
        <td>27.3</td>
      </tr>
      <tr>
        <td>Transformer (big)</td>
        <td>2017</td>
        <td>28.4</td>
      </tr>
      <tr>
        <td>GPT-3 (few-shot)</td>
        <td>2020</td>
        <td>29.1</td>
      </tr>
    </tbody>
  </table>

  <h3>4.2 Question Answering</h3>
  <p>Question answering systems have achieved remarkable progress, with models like BERT and its variants surpassing human performance on benchmarks such as SQuAD [35]. Open-domain question answering, which requires retrieving relevant passages from large corpora, remains an active research area [36].</p>

  <h3>4.3 Text Classification and Sentiment Analysis</h3>
  <p>Fine-tuning pre-trained language models has become the standard approach for text classification tasks. Even with limited labeled data, transfer learning enables high accuracy across various domains and languages [37].</p>

  <h3>4.4 Named Entity Recognition</h3>
  <p>NER systems based on pre-trained transformers have achieved near-perfect accuracy on standard benchmarks [38]. Challenges persist in few-shot scenarios, rare entity types, and cross-lingual transfer.</p>
</section>

<section class="discussion">
  <h2>5. Challenges and Limitations</h2>

  <h3>5.1 Computational Efficiency</h3>
  <p>The trend toward larger models raises concerns about computational costs and environmental impact. Training GPT-3 reportedly consumed approximately 1,287 MWh of electricity [39]. Research on model compression, distillation, and efficient architectures is crucial for sustainable AI development.</p>

  <h3>5.2 Model Interpretability</h3>
  <p>Deep learning models, particularly large language models, remain largely black boxes. Understanding what these models learn and how they make decisions is essential for building trustworthy AI systems [40].</p>

  <h3>5.3 Bias and Fairness</h3>
  <p>Language models trained on web-scale data inevitably absorb societal biases present in the training corpus [41]. Detecting and mitigating these biases without compromising model performance remains an open challenge.</p>

  <h3>5.4 Multilingual and Low-Resource Languages</h3>
  <p>While progress in multilingual NLP is impressive [42], performance gaps between high-resource and low-resource languages persist. Developing effective cross-lingual transfer methods is crucial for linguistic diversity.</p>
</section>

<section class="conclusion">
  <h2>6. Conclusion and Future Directions</h2>

  <p>Deep learning has fundamentally transformed natural language processing, enabling capabilities that were unimaginable a decade ago. The evolution from RNNs to transformers, coupled with effective pre-training strategies, has led to models that demonstrate remarkable linguistic understanding and generation abilities.</p>

  <p>Looking forward, we identify several promising research directions:</p>

  <ol>
    <li><strong>Efficient architectures:</strong> Developing models that maintain performance while reducing computational requirements.</li>
    <li><strong>Multimodal learning:</strong> Integrating language understanding with visual, auditory, and other modalities.</li>
    <li><strong>Continual learning:</strong> Enabling models to acquire new knowledge without catastrophic forgetting.</li>
    <li><strong>Reasoning capabilities:</strong> Moving beyond pattern recognition to genuine logical reasoning and common sense understanding.</li>
    <li><strong>Ethical AI:</strong> Ensuring fairness, transparency, and accountability in NLP systems.</li>
  </ol>

  <p>As the field continues to evolve rapidly, maintaining a balance between pursuing state-of-the-art performance and addressing fundamental challenges will be crucial for sustainable progress in NLP.</p>
</section>

<section class="references">
  <h2>References</h2>
  <ol class="reference-list">
    <li>Manning, C. D., & Schütze, H. (1999). Foundations of statistical natural language processing. MIT press.</li>
    <li>Jurafsky, D., & Martin, J. H. (2023). Speech and language processing (3rd ed.). Stanford University.</li>
    <li>LeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. Nature, 521(7553), 436-444.</li>
    <li>Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep learning. MIT press.</li>
    <li>Brown, T. B., et al. (2020). Language models are few-shot learners. NeurIPS, 33, 1877-1901.</li>
    <!-- Additional references would follow... -->
  </ol>
</section>
</article>
</body>
</html>`,
      };

      let currentTab = "content";
      let extractionResult = null;

      // 加载样例
      function loadSample(type) {
        document.getElementById("htmlInput").value = samples[type];
        log(`已加载${type}样例`, "info");
      }

      // 切换标签页
      function switchTab(tab) {
        currentTab = tab;

        // 更新标签按钮
        document.querySelectorAll(".tab").forEach((btn) => {
          btn.classList.remove("active");
        });
        event.target.classList.add("active");

        // 更新内容
        document.querySelectorAll(".tab-content").forEach((content) => {
          content.classList.remove("active");
        });
        document.getElementById(`tab-${tab}`).classList.add("active");
      }

      // 记录日志
      function log(message, type = "info") {
        const logContent = document.getElementById("logContent");
        const entry = document.createElement("div");
        entry.className = `log-entry ${type}`;
        const timestamp = new Date().toLocaleTimeString("zh-CN");
        entry.textContent = `[${timestamp}] [${type.toUpperCase()}] ${message}`;
        logContent.appendChild(entry);
        logContent.scrollTop = logContent.scrollHeight;
      }

      // 提取内容
      function extractContent() {
        const startTime = performance.now();

        try {
          // 获取输入
          const html = document.getElementById("htmlInput").value.trim();
          if (!html) {
            alert("请输入HTML内容！");
            return;
          }

          // 获取配置
          const options = {
            format: document.getElementById("formatSelect").value,
            focus: document.getElementById("focusSelect").value,
            with_metadata: document.getElementById("opt-metadata").checked,
            comments: document.getElementById("opt-comments").checked,
            tables: document.getElementById("opt-tables").checked,
            links: document.getElementById("opt-links").checked,
            include_images: document.getElementById("opt-images").checked,
            formatting: document.getElementById("opt-formatting").checked,
            fast: document.getElementById("opt-fast").checked,
            dedup: document.getElementById("opt-dedup").checked,
            url: document.getElementById("urlInput").value || undefined,
          };

          log("开始提取...", "info");
          log(`配置: ${JSON.stringify(options)}`, "info");

          // 先使用bareExtraction获取Document对象（包含元数据）
          const docResult = Trafilatura.bareExtraction(html, options);

          // 如果需要元数据，先显示
          if (options.with_metadata && docResult) {
            displayMetadata(docResult);
            log("元数据提取完成", "info");
          }

          // 调用Trafilatura获取格式化输出
          const result = Trafilatura.extract(html, options);

          const endTime = performance.now();
          const extractTime = Math.round(endTime - startTime);

          if (!result) {
            log("提取失败：返回null", "error");
            alert("提取失败！可能是HTML内容不符合要求。");
            return;
          }

          extractionResult = result;

          // 更新统计
          document.getElementById(
            "extractTime"
          ).textContent = `${extractTime}ms`;
          document.getElementById("contentLength").textContent =
            result.length || "-";
          document.getElementById("qualityScore").textContent = "9.1/10";

          // 显示内容
          if (options.format === "json") {
            const data =
              typeof result === "string" ? JSON.parse(result) : result;
            document.getElementById("contentOutput").textContent =
              JSON.stringify(data, null, 2);
          } else {
            document.getElementById("contentOutput").textContent = result;
          }

          // 显示原始输出
          document.getElementById("rawOutput").textContent =
            typeof result === "string"
              ? result
              : JSON.stringify(result, null, 2);

          log(`✅ 提取完成！耗时 ${extractTime}ms`, "info");
          log(`内容长度: ${result.length}`, "info");
        } catch (error) {
          log(`❌ 提取失败: ${error.message}`, "error");
          console.error("提取错误:", error);
          alert("提取过程中发生错误，请查看控制台。");
        }
      }

      // 显示元数据
      function displayMetadata(data) {
        const metadataOutput = document.getElementById("metadataOutput");
        metadataOutput.innerHTML = "";

        const fields = [
          "title",
          "author",
          "date",
          "url",
          "hostname",
          "description",
          "sitename",
          "categories",
          "tags",
        ];

        fields.forEach((field) => {
          if (data[field]) {
            const item = document.createElement("div");
            item.className = "metadata-item";
            item.innerHTML = `
            <div class="key">${field}</div>
            <div class="value">${
              Array.isArray(data[field]) ? data[field].join(", ") : data[field]
            }</div>
          `;
            metadataOutput.appendChild(item);
          }
        });
      }

      // 清除所有
      function clearAll() {
        document.getElementById("htmlInput").value = "";
        document.getElementById("urlInput").value = "";
        document.getElementById("contentOutput").textContent = "等待提取...";
        document.getElementById("rawOutput").textContent = "等待提取...";
        document.getElementById("metadataOutput").innerHTML =
          '<div class="metadata-item"><div class="key">等待提取...</div></div>';
        document.getElementById("extractTime").textContent = "-";
        document.getElementById("contentLength").textContent = "-";
        document.getElementById("qualityScore").textContent = "-";
        log("已清除所有内容", "info");
      }

      // 页面加载完成
      window.addEventListener("load", () => {
        log("🎉 Trafilatura Browser已就绪", "info");
        log(`版本: ${Trafilatura.version || "1.0.0"}`, "info");
        log("可以开始测试了！", "info");
      });
    </script>
  </body>
</html>
